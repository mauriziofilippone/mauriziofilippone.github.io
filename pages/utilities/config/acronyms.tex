\newacronym{MAP}{map}{maximum-a-posteriori}
\newacronym{MLE}{mle}{maximum likelihood estimation}
\newacronym{MNLL}{mnll}{mean negative loglikelihood}
\newacronym{NLL}{nll}{negative loglikelihood}
\newacronym{RMSE}{rmse}{root mean square error}
\newacronym{ECE}{ece}{expected calibration error}

\newacronym{VAE}{vae}{variational autoencoder}

\newacronym{MC}{mc}{Monte Carlo}
\newacronym{MCMC}{mcmc}{Markov chain Monte Carlo}
\newacronym{HMC}{hmc}{Hamiltonian Monte Carlo}
\newacronym{MH}{mh}{Metropolis-Hastings}
\newacronym{NUTS}{nuts}{no-u-turn sampler}
\newacronym{SGHMC}{sghmc}{stochastic gradient Hamiltonian Monte Carlo}

% \newacronym{GP}{gp}{Gaussian process}
\newacronym{DGP}{dgp}{deep Gaussian process} % use glspl for plural
\newacronym{GPLVM}{gplvm}{Gaussian process latent variable model}

\newacronym{VFE}{vfe}{variational free energy}

\newacronym[firstplural=Gaussian Processes]{GP}{gp}{Gaussian Process}
%\newacronym[plural=dgp\textnormal{s}, firstplural=Deep Gaussian Processes]{DGP}{dgp}{Deep Gaussian Process}

\newacronym{VI}{vi}{variational inference}

\newacronym{ELBO}{elbo}{evidence lower bound}
\newacronym{NELBO}{nelbo}{negative evidence lower bound}
\newacronym{ELL}{ell}{expected log likelihood}
\newacronym{KL}{kl}{Kullback-Leibler divergence}
\newacronym{AUC}{auc}{area under the curve}

\newacronym[firstplural=Bayesian neural networks]{BNN}{bnn}{Bayesian neural network}
\newacronym[firstplural=deep neural networks]{DNN}{dnn}{deep neural network}
\newacronym[]{CNN}{cnn}{convolutional neural network}
\newacronym{MLP}{mlp}{multilayer perceptron}
\newacronym{NN}{nn}{neural network}
\newacronym{RELU}{ReLU}{rectified linear unit}

\newacronym{NF}{nf}{normalizing flow}

\newacronym{RBF}{rbf}{radial basis function}
\newacronym{ARD}{ard}{automatic relevance determination}

\newacronym{RKHS}{rkhs}{reproducing kernel Hilbert space}

\newcommand{\iid}{i.i.d~} 

